# -*- coding: utf-8 -*-
"""marine-pollution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C2C6sDDDrpRkFeO80aVK2U8FrCPcBx4f
"""

# no 1

from pyspark.sql import SparkSession
from pyspark.sql.functions import when
from pyspark.ml.feature import VectorAssembler,StandardScaler
from pyspark.ml.clustering import KMeans
from matplotlib import pyplot as plt

spark = SparkSession.builder.getOrCreate()

df_train = spark.read.option("inferSchema", "true").csv("Clustering_Training.csv", header=True)
df_test = spark.read.option("inferSchema", "true").csv("Clustering_Testing.csv", header=True)

df_train.show()

# select features
df_train = df_train.select("Trash Pollution", "Oil Concentration", "Algae Concentration")
df_test = df_test.select("Trash Pollution", "Oil Concentration", "Algae Concentration", "Polluted")

# data pre processing
df_train = df_train.na.drop()
df_test = df_test.na.drop()

# transform
def transform(df):
    df = df.withColumn("Trash Pollution", when(df["Trash Pollution"] == "Low", 0).when(df["Trash Pollution"] == "Medium", 1).otherwise(2))
    return df

df_train = transform(df_train)
df_test = transform(df_test)

df_test = df_test.withColumn("Polluted", when(df_test["Polluted"] == "No", 0).otherwise(1))

# normalisasi
cols = df_train.columns
# gabungin banyak kolom jd 1, nama Vector Features bebas
df_train = VectorAssembler(inputCols = cols, outputCol = "Vector Features").transform(df_train)
df_train = StandardScaler(inputCol = "Vector Features", outputCol = "features").fit(df_train).transform(df_train)
# nama features fixed krn pake kmeans nyari features

cols = df_test.columns
cols.remove("Polluted")
df_test = VectorAssembler(inputCols = cols, outputCol = "Vector Features").transform(df_test)
df_test = StandardScaler(inputCol = "Vector Features", outputCol = "features").fit(df_test).transform(df_test)


# generate model
kmeans = KMeans().setK(2).setSeed(1)
# set mode clustering: 2 (polluted and non polluted)
# 1 berapa kali ambil sample yg sama setiap clustering
model = kmeans.fit(df_train)
predictions = model.transform(df_test)

predictions.show()

# visualization
predictions = predictions.toPandas()
plt.scatter(predictions["Algae Concentration"], predictions["Oil Concentration"], c = predictions["prediction"])
plt.xlabel("Algae Concentration")
plt.ylabel("Oil Concentration")
plt.title("Clustering")

plt.show()
# df_train.show()
# df_test.show()

# evaluation
count = 0
for idx, n in predictions.iterrows():
    if n["prediction"] == n["Polluted"]:
        count = count + 1

print(f"Accuracy: {count / len(predictions) * 100}%")